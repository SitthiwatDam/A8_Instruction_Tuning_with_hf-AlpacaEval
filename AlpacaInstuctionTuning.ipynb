{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5896b1a6-8ed4-4484-96e5-50d0ac10b73a",
   "metadata": {},
   "source": [
    "# Alpaca Instuction Tuning Evalutation\n",
    "Name: Sitthiwat Damrongpreechar <br>\n",
    "StudentID: st123994"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13f636b5-91b3-4a45-a6cf-334425eac4df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# install libraries\n",
    "# !pip3 install peft==0.7.1\n",
    "# !pip3 install trl==0.7.4\n",
    "# !pip3 install transformer==4.36.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fd24274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('4.36.2', '0.7.4')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers, trl\n",
    "transformers.__version__,trl.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "74ed1948-2b9b-4324-ba26-36b6c95fdbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# setting up the device\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37844865",
   "metadata": {},
   "source": [
    "## 1. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1ea5ec-482c-4520-bd97-3ccc1f2961f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset \"alpaca_data.json\"\n",
    "from datasets import load_dataset\n",
    "train_dataset = load_dataset('json', data_files='./alpaca_data.json', split='train')\n",
    "eval_dataset = load_dataset(\"tatsu-lab/alpaca_eval\", split='eval', trust_remote_code=True)\n",
    "eval_dataset = eval_dataset.remove_columns([\"generator\", \"dataset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1618d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'output', 'input'],\n",
       "    num_rows: 52002\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13648079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['instruction', 'output'],\n",
       "    num_rows: 805\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40b26095",
   "metadata": {},
   "source": [
    "## 2. Load the model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "69100196-d9d8-4791-9e11-6e93f1bd7550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\earth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\transformers\\utils\\generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "model_name_or_path = \"distilgpt2\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name_or_path, device_map = 'auto')\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_name_or_path)\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "# Make sure to pass a correct value for max_seq_length as the default value will be set to min(tokenizer.model_max_length, 1024).\n",
    "max_seq_length = min(tokenizer.model_max_length, 1024)\n",
    "max_seq_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "81d350a2-002b-40e2-8c10-9afea5923cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def formatting_prompts_func(examples):\n",
    "\toutput_texts = []\n",
    "\n",
    "\tfor i in range(len(examples['instruction'])):\n",
    "\t\tif 'input' in examples.keys():\n",
    "\t\t\tinput_text = examples[\"input\"][i] \n",
    "\t\telse:\n",
    "\t\t\tinput_text = None\n",
    "\t\n",
    "\t\tif input_text:\n",
    "\t\t\ttext = f\"\"\"\n",
    "Below is an instruction for an instruction-tuning task, paired with an input that provides further context. Write a response that appropriately aligns with the provided instruction.\n",
    "\n",
    "### Instruction:\n",
    "{examples[\"instruction\"][i]}\n",
    "\n",
    "### Input:\n",
    "{input_text}\n",
    "\n",
    "### Response:\n",
    "{examples[\"output\"][i]}\n",
    "\"\"\".strip()\n",
    "\t\t\t\n",
    "\t\telse:\n",
    "\t\t\ttext = f\"\"\"\n",
    "Below is an instruction for an instruction-tuning task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{examples[\"instruction\"][i]}\n",
    "\n",
    "### Response:\n",
    "{examples[\"output\"][i]}\n",
    "\"\"\".strip()\n",
    "\n",
    "\t\toutput_texts.append(text)\n",
    "\n",
    "\treturn output_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8a26c01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataCollatorForCompletionOnlyLM(tokenizer=GPT2TokenizerFast(name_or_path='distilgpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "}, mlm=False, mlm_probability=0.15, pad_to_multiple_of=None, tf_experimental_compile=False, return_tensors='pt')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use the DataCollatorForCompletionOnlyLM to train your model on the generated prompts only\n",
    "from trl import SFTTrainer, DataCollatorForCompletionOnlyLM\n",
    "response_template = \"### Response:\"\n",
    "collator = DataCollatorForCompletionOnlyLM(response_template, tokenizer=tokenizer)\n",
    "collator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6300c234",
   "metadata": {},
   "source": [
    "## 4. Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28385087-8eb8-4b83-a7dd-1313bf591b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "# path to save the model\n",
    "path = './checkpoints'\n",
    "# TrainingArguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = path, #default = 'tmp_trainer'\n",
    "    save_strategy = 'epoch',\n",
    "    gradient_checkpointing = True,\n",
    "    per_device_train_batch_size = 2,\n",
    "    per_device_eval_batch_size = 2,\n",
    "    num_train_epochs = 5, #default = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90e4a3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the SFTTrainer\n",
    "trainer = SFTTrainer(\n",
    "    model,\n",
    "    args = training_args,\n",
    "    train_dataset = train_dataset.select(range(10000)),\n",
    "    eval_dataset = eval_dataset,\n",
    "    formatting_func = formatting_prompts_func,\n",
    "    data_collator = collator,\n",
    "    max_seq_length = max_seq_length,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eeef5ad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5058f23c839146fb86be5c1c72a8e766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`...\n",
      "c:\\Users\\earth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.6757, 'learning_rate': 4.9e-05, 'epoch': 0.1}\n",
      "{'loss': 2.6376, 'learning_rate': 4.8e-05, 'epoch': 0.2}\n",
      "{'loss': 2.5541, 'learning_rate': 4.7e-05, 'epoch': 0.3}\n",
      "{'loss': 2.5301, 'learning_rate': 4.600000000000001e-05, 'epoch': 0.4}\n",
      "{'loss': 2.4877, 'learning_rate': 4.5e-05, 'epoch': 0.5}\n",
      "{'loss': 2.5148, 'learning_rate': 4.4000000000000006e-05, 'epoch': 0.6}\n",
      "{'loss': 2.4772, 'learning_rate': 4.3e-05, 'epoch': 0.7}\n",
      "{'loss': 2.4441, 'learning_rate': 4.2e-05, 'epoch': 0.8}\n",
      "{'loss': 2.4245, 'learning_rate': 4.1e-05, 'epoch': 0.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./checkpoints\\checkpoint-5000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4522, 'learning_rate': 4e-05, 'epoch': 1.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\earth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1088, 'learning_rate': 3.9000000000000006e-05, 'epoch': 1.1}\n",
      "{'loss': 2.1369, 'learning_rate': 3.8e-05, 'epoch': 1.2}\n",
      "{'loss': 2.1237, 'learning_rate': 3.7e-05, 'epoch': 1.3}\n",
      "{'loss': 2.1234, 'learning_rate': 3.6e-05, 'epoch': 1.4}\n",
      "{'loss': 2.159, 'learning_rate': 3.5e-05, 'epoch': 1.5}\n",
      "{'loss': 2.0861, 'learning_rate': 3.4000000000000007e-05, 'epoch': 1.6}\n",
      "{'loss': 2.1244, 'learning_rate': 3.3e-05, 'epoch': 1.7}\n",
      "{'loss': 2.1155, 'learning_rate': 3.2000000000000005e-05, 'epoch': 1.8}\n",
      "{'loss': 2.1202, 'learning_rate': 3.1e-05, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./checkpoints\\checkpoint-10000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.1443, 'learning_rate': 3e-05, 'epoch': 2.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\earth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8731, 'learning_rate': 2.9e-05, 'epoch': 2.1}\n",
      "{'loss': 1.8856, 'learning_rate': 2.8000000000000003e-05, 'epoch': 2.2}\n",
      "{'loss': 1.8842, 'learning_rate': 2.7000000000000002e-05, 'epoch': 2.3}\n",
      "{'loss': 1.8713, 'learning_rate': 2.6000000000000002e-05, 'epoch': 2.4}\n",
      "{'loss': 1.9378, 'learning_rate': 2.5e-05, 'epoch': 2.5}\n",
      "{'loss': 1.9428, 'learning_rate': 2.4e-05, 'epoch': 2.6}\n",
      "{'loss': 1.8922, 'learning_rate': 2.3000000000000003e-05, 'epoch': 2.7}\n",
      "{'loss': 1.8466, 'learning_rate': 2.2000000000000003e-05, 'epoch': 2.8}\n",
      "{'loss': 1.8869, 'learning_rate': 2.1e-05, 'epoch': 2.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./checkpoints\\checkpoint-15000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8921, 'learning_rate': 2e-05, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\earth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6852, 'learning_rate': 1.9e-05, 'epoch': 3.1}\n",
      "{'loss': 1.7027, 'learning_rate': 1.8e-05, 'epoch': 3.2}\n",
      "{'loss': 1.7658, 'learning_rate': 1.7000000000000003e-05, 'epoch': 3.3}\n",
      "{'loss': 1.7696, 'learning_rate': 1.6000000000000003e-05, 'epoch': 3.4}\n",
      "{'loss': 1.7077, 'learning_rate': 1.5e-05, 'epoch': 3.5}\n",
      "{'loss': 1.7048, 'learning_rate': 1.4000000000000001e-05, 'epoch': 3.6}\n",
      "{'loss': 1.7765, 'learning_rate': 1.3000000000000001e-05, 'epoch': 3.7}\n",
      "{'loss': 1.7471, 'learning_rate': 1.2e-05, 'epoch': 3.8}\n",
      "{'loss': 1.7026, 'learning_rate': 1.1000000000000001e-05, 'epoch': 3.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checkpoint destination directory ./checkpoints\\checkpoint-20000 already exists and is non-empty.Saving will proceed but saved results may be invalid.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7427, 'learning_rate': 1e-05, 'epoch': 4.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\earth\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6179, 'learning_rate': 9e-06, 'epoch': 4.1}\n",
      "{'loss': 1.5883, 'learning_rate': 8.000000000000001e-06, 'epoch': 4.2}\n",
      "{'loss': 1.6334, 'learning_rate': 7.000000000000001e-06, 'epoch': 4.3}\n",
      "{'loss': 1.6035, 'learning_rate': 6e-06, 'epoch': 4.4}\n",
      "{'loss': 1.5947, 'learning_rate': 5e-06, 'epoch': 4.5}\n",
      "{'loss': 1.6386, 'learning_rate': 4.000000000000001e-06, 'epoch': 4.6}\n",
      "{'loss': 1.6409, 'learning_rate': 3e-06, 'epoch': 4.7}\n",
      "{'loss': 1.5751, 'learning_rate': 2.0000000000000003e-06, 'epoch': 4.8}\n",
      "{'loss': 1.5951, 'learning_rate': 1.0000000000000002e-06, 'epoch': 4.9}\n",
      "{'loss': 1.6271, 'learning_rate': 0.0, 'epoch': 5.0}\n",
      "{'train_runtime': 2296.3844, 'train_samples_per_second': 21.773, 'train_steps_per_second': 10.887, 'train_loss': 1.9754472119140625, 'epoch': 5.0}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=25000, training_loss=1.9754472119140625, metrics={'train_runtime': 2296.3844, 'train_samples_per_second': 21.773, 'train_steps_per_second': 10.887, 'train_loss': 1.9754472119140625, 'epoch': 5.0})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8eae0de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model('./app/model')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cd24cc",
   "metadata": {},
   "source": [
    "## 5. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5da45651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "# load the model that we just trained\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    './app/model',\n",
    "    device_map = 'auto')\n",
    "# create a text generation pipeline\n",
    "text_generator = pipeline(\n",
    "    \"text-generation\",\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    pad_token_id = tokenizer.eos_token_id,\n",
    "    max_new_tokens = 50,\n",
    "    device_map = 'auto',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0a07a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate prompt for the model\n",
    "def Generate_prompt_input(text):\n",
    "\t\n",
    "\tif 'input' in text.keys():\n",
    "\t\treturn f\"\"\"\n",
    "Below is an instruction for an instruction-tuning task, paired with an input that provides further context. Write a response that appropriately aligns with the provided instruction.\n",
    "\n",
    "### Instruction:\n",
    "{text['instruction']}\n",
    "\n",
    "### Input:\n",
    "{text['input']}\n",
    "\n",
    "### Response:\n",
    "\"\"\".strip()\n",
    "\t\t\t\n",
    "\telse:\n",
    "\t\treturn f\"\"\"\n",
    "Below is an instruction for an instruction-tuning task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{text['instruction']}\n",
    "\n",
    "### Response:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fedea2f",
   "metadata": {},
   "source": [
    "## 6. Comparing your generated result with gold label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd01f69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction for an instruction-tuning task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "What are the names of some famous actors that started their careers on Broadway?\n",
      "\n",
      "### Response:\n",
      "Some famous actors that started their careers on Broadway include Emma Stone and Al Pacino. Those actors include Rose McGowan and John Boyega. Other famous names include Mary Sue DeWittder and Rose Gardenz. Most famous actors also include Whitney \n",
      "\n",
      "### GOLD LABEL:\n",
      "Some famous actors that started their careers on Broadway include: \n",
      "1. Hugh Jackman \n",
      "2. Meryl Streep \n",
      "3. Denzel Washington \n",
      "4. Julia Roberts \n",
      "5. Christopher Walken \n",
      "6. Anthony Rapp \n",
      "7. Audra McDonald \n",
      "8. Nathan Lane \n",
      "9. Sarah Jessica Parker \n",
      "10. Lin-Manuel Miranda\n"
     ]
    }
   ],
   "source": [
    "result = text_generator(Generate_prompt_input(eval_dataset[0]))\n",
    "print(result[0]['generated_text'],\"\\n\")\n",
    "print(f\"### GOLD LABEL:\\n{eval_dataset['output'][0]}\") #gold label"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
